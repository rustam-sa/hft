{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_service import DataService\n",
    "\n",
    "eth_ds = DataService(\"ETH-USDT\", \"3min\")\n",
    "eth_data = eth_ds.load_market_data()\n",
    "\n",
    "btc_ds = DataService(\"BTC-USDT\", \"3min\")\n",
    "btc_data = btc_ds.load_market_data()\n",
    "btc_data.columns = [col + \"_btc\" if col != 'timestamp' else col for col in btc_data.columns]\n",
    "df = pd.merge(eth_data, btc_data, on='timestamp', how='inner')\n",
    "display(df.tail(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['id', 'symbol', 'id_btc', 'symbol_btc', 'timeframe_btc', 'timeframe'], axis=1)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cross_validation\n",
    "\n",
    "cross_val_count = 3\n",
    "train_segment_size = 300000\n",
    "val_segment_size = 50000\n",
    "test_segment_size = 50000\n",
    "cross_val_segmentation_map = cross_validation.create_segmentation_map(cross_val_count, train_segment_size, val_segment_size, test_segment_size)\n",
    "display(cross_val_segmentation_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.tail(cross_val_segmentation_map['total_data_needed']).reset_index(drop=True)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = {}\n",
    "for n in range(cross_val_count):\n",
    "    cross_val_cycle_keys = [key for key in cross_val_segmentation_map.keys() if str(n) in key]\n",
    "    \n",
    "    segments[n] = {}\n",
    "    for key in cross_val_cycle_keys:\n",
    "        start_end_tuple = cross_val_segmentation_map[key]\n",
    "        segment = cross_validation.get_segment(df, *start_end_tuple)\n",
    "        segments[n][key] = segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_set_n = 2\n",
    "cross_val_set = segments[cross_val_set_n]\n",
    "train_data = cross_val_set[f'train_segment_{cross_val_set_n}']\n",
    "val_data = cross_val_set[f'val_segment_{cross_val_set_n}']\n",
    "test_data = cross_val_set[f'test_segment_{cross_val_set_n}']\n",
    "\n",
    "train_data = train_data.drop(['timestamp'], axis=1)\n",
    "val_data = val_data.drop(['timestamp'], axis=1)\n",
    "test_data = test_data.drop(['timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from labeler import BinaryWinFinder\n",
    "\n",
    "win_direction, candle_span, distance_threshold = \"long\", 500, 0.01\n",
    "\n",
    "steps = np.linspace(5, 250, 50)\n",
    "steps = [int(n) for n in steps]\n",
    "\n",
    "\n",
    "def create_labels(df):\n",
    "    win_finder = BinaryWinFinder(df, win_direction, candle_span, distance_threshold)\n",
    "    df['wins'] = win_finder.find_wins()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_scaler(scaler_fit_data):\n",
    "    scaler = RobustScaler()\n",
    "    scaler = scaler.fit(scaler_fit_data)\n",
    "    return scaler\n",
    "\n",
    "\n",
    "def ema(df, span, target_col):\n",
    "    closes = df[target_col]\n",
    "    ema = closes.ewm(span=span).mean()\n",
    "    label = f\"{target_col}_ema_{span}\"\n",
    "    return ema.rename(label)\n",
    "\n",
    "\n",
    "def apply_emas(df):\n",
    "    df = df.copy()\n",
    "    for n in steps:\n",
    "        series = ema(df, n, 'close')\n",
    "        df[series.name] = series\n",
    "        series = ema(df, n, 'close_btc')\n",
    "        df[series.name] = series\n",
    "    return df\n",
    "\n",
    "\n",
    "def log_series_if_ascending(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = np.log(df[column])\n",
    "        print(f\"Log transformation applied on column '{column}'\")\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_X_and_y(df):\n",
    "    y = df['wins'].reset_index(drop=True)\n",
    "    X = df.drop(['wins'], axis=1).reset_index(drop=True)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def atr(df, period=14):\n",
    "    high_column = df['high']\n",
    "    low_column = df['low']\n",
    "    prev_close_column = df['close'].shift(-1)\n",
    "    high_low_arr = high_column - low_column\n",
    "    high_close_arr = abs(high_column - prev_close_column)\n",
    "    low_close_arr = abs(low_column - prev_close_column)\n",
    "    tr = pd.concat([high_low_arr, high_close_arr, low_close_arr], axis=1).max(axis=1)\n",
    "    atr = tr.ewm(alpha=1/period, adjust=False).mean()\n",
    "    label = f\"atr{period}\"\n",
    "    return atr.rename(label)\n",
    "\n",
    "\n",
    "def obv(df):\n",
    "    copy = df.copy()\n",
    "    obv = (np.sign(copy[\"close\"].diff()) * copy[\"volume\"]).fillna(0).rolling(250).sum()\n",
    "    return obv\n",
    "\n",
    "\n",
    "def process(df, scaler):\n",
    "    df = create_labels(df)\n",
    "    df = apply_emas(df)\n",
    "    df['atr'] = atr(df)\n",
    "    df['obv'] = obv(df)\n",
    "    cols_not_win = [col for col in df.columns if col != \"wins\"]\n",
    "    df[cols_not_win] = scaler.transform(df[cols_not_win])\n",
    "    df[cols_not_win] = df[cols_not_win].pct_change(1)\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.dropna()\n",
    "    X, y = get_X_and_y(df)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_emas = apply_emas(train_data.copy())\n",
    "train_data_with_emas['atr'] = atr(train_data_with_emas)\n",
    "train_data_with_emas['obv'] = obv(train_data_with_emas)\n",
    "# cols_not_win = [col for col in train_data_with_emas.columns if col != \"wins\"]\n",
    "# train_data_with_emas[cols_not_win] = train_data_with_emas[cols_not_win].pct_change(1)\n",
    "# train_data_with_emas.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# train_data_with_emas.dropna(inplace=True)\n",
    "scaler = get_scaler(train_data_with_emas)\n",
    "X_train, y_train = process(train_data, scaler)\n",
    "X_val, y_val = process(val_data, scaler)\n",
    "X_test, y_test = process(test_data, scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'alpha': trial.suggest_float('alpha', 0.1, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 0.1, 1.0),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10),\n",
    "        'early_stopping_rounds': 10\n",
    "    }\n",
    "    \n",
    "    model = XGBClassifier(**param, use_label_encoder=False, eval_metric='logloss')\n",
    "    \n",
    "    # Train the model on the training set\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "    \n",
    "    # Make predictions on the validation set\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    threshold = 0.75 # Adjust this threshold value as needed\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Evaluate the model on the validation set for the positive class (class 1)\n",
    "    precision = precision_score(y_val, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_val, y_pred, pos_label=1)\n",
    "    \n",
    "    # Custom metric that combines precision and recall smoothly\n",
    "    score = precision * 0.75 + recall * 0.25\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import precision_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize the model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "best_params['use_label_encoder'] = False\n",
    "best_params['eval_metric'] = 'logloss'\n",
    "best_params['early_stopping_rounds'] = 10\n",
    "\n",
    "model = XGBClassifier(**best_params)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train , eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "# Make predictions\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "threshold = 0.75 # Adjust this threshold value as needed\n",
    "y_pred = (y_proba >= threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hft-2GmTtn1u",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
